{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PolygonDatasetGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SCBJxAI4OSlh",
        "colab": {}
      },
      "source": [
        "from PIL import Image, ImageStat\n",
        "from PIL.ImageDraw import ImageDraw\n",
        "\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from random import randint\n",
        "from math import pi\n",
        "\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "from fastai import vision\n",
        "from fastai.vision import ImageList, FloatList, cnn_learner, pil2tensor, open_image\n",
        "from fastai.callbacks import EarlyStoppingCallback, ReduceLROnPlateauCallback, CSVLogger\n",
        "from fastai.train import ShowGraph, Learner\n",
        "from fastai.metrics import mean_absolute_error, mean_squared_error\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "\n",
        "from functools import partial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am0BMzMJmCVH",
        "colab_type": "text"
      },
      "source": [
        "## Funcoes Auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owaoIerimCVM",
        "colab_type": "text"
      },
      "source": [
        "### Model Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yeben-JAOixI",
        "jupyter": {
          "source_hidden": true
        },
        "colab": {}
      },
      "source": [
        "def base_layer(conv_args, pool_layer, pool_size, activation_fn):\n",
        "    return nn.Sequential(nn.Conv2d(**conv_args), pool_layer(pool_size), activation_fn())\n",
        "        \n",
        "\n",
        "\n",
        "def base_model(max_channels, activation_fn, pool_layer, pool_size, num_layers, conv_stride=1):\n",
        "    return nn.Sequential(\n",
        "        *[base_layer({\n",
        "            \"in_channels\": i if i < max_channels else max_channels, \n",
        "            \"out_channels\": abs(i+1) if i < max_channels else max_channels,\n",
        "            \"kernel_size\": 3,\n",
        "            \"stride\": conv_stride\n",
        "            }, pool_layer, pool_size, activation_fn) for i in range(1, num_layers//2 + 1)],\n",
        "        *[base_layer({\n",
        "            \"in_channels\": i if i < max_channels else max_channels,\n",
        "            \"out_channels\": i - 1 if i - 1 < max_channels else max_channels,\n",
        "            \"kernel_size\": 3,\n",
        "            \"stride\": conv_stride \n",
        "        }, pool_layer, pool_size, activation_fn) for i in range(num_layers//2 + 1, 1, -1)]\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "class SumPool2d(nn.Module):\n",
        "    def __init__(self, pool_size):\n",
        "        super(SumPool2d, self).__init__()\n",
        "        self.pool_size = pool_size\n",
        "        self.area = pool_size * pool_size\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return F.avg_pool2d(x, self.pool_size) * self.area"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2arhmyAmCVb",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Generation Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "jupyter": {
          "source_hidden": true
        },
        "id": "iE4Wp6sRmCVe",
        "colab": {}
      },
      "source": [
        "def random_point(w, h, minx=0, miny=0):\n",
        "    x, y = randint(minx, w), randint(miny, h)\n",
        "    return (x, y)\n",
        "\n",
        "def area_ellipse(p1, p2):\n",
        "    x1, y1 = p1\n",
        "    x2, y2 = p2\n",
        "    x_len = abs(x1 - x2)\n",
        "    y_len = abs(y1 - y2)\n",
        "    return pi * x_len * y_len\n",
        "\n",
        "def gen_example(w, h, num_polygons=1, count=False):\n",
        "    example = Image.new('1', (w, h))\n",
        "    draw = ImageDraw(example, mode='1')\n",
        "\n",
        "    total_area = w * h\n",
        "    area = 0\n",
        "    for i in range(num_polygons):\n",
        "        p1 = random_point(w, h)\n",
        "        p2 = random_point(w, h, p1[0], p1[1])\n",
        "        draw.rectangle([p1, p2], fill=1)\n",
        "\n",
        "    (area, ) = ImageStat.Stat(example).sum\n",
        "    if not count:\n",
        "        area /= total_area\n",
        "    return (example, area)\n",
        "\n",
        "def gen_df(\n",
        "        root_dir, \n",
        "        dt_len, \n",
        "        img_size=(512, 512), \n",
        "        skip=True, \n",
        "        test=False, \n",
        "        count=False):\n",
        "    root_dir = path.abspath(root_dir)\n",
        "    root_dir = path.join(root_dir, \"test\" if test else \"train\")\n",
        "    img_dir = path.join(root_dir, 'images')\n",
        "    df_dest = path.join(root_dir, 'data.csv')\n",
        "    if path.exists(df_dest) and skip:\n",
        "        print(\"Found existing dataset, skipping...\")\n",
        "        return pd.read_csv(df_dest, index_col=0)\n",
        "    \n",
        "    for directory in [root_dir, img_dir]:\n",
        "        if not path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "            print(f\"Created directory {directory}\")\n",
        "\n",
        "    df = pd.DataFrame(columns=['filename', 'area'])\n",
        "    for i in range(dt_len):\n",
        "        filename = f\"img_{i}.jpeg\"\n",
        "        dest_path = path.join(img_dir, filename)\n",
        "        img, area = gen_example(*img_size, count=count)\n",
        "        img.save(dest_path)\n",
        "        row = pd.Series({\"filename\": filename, \"area\": area})\n",
        "        df.loc[i] = row\n",
        "\n",
        "    df.to_csv(df_dest)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV6aql7AmCVm",
        "colab_type": "text"
      },
      "source": [
        "### Results Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "jupyter": {
          "source_hidden": true
        },
        "id": "kCO0z1fomCVp",
        "colab": {}
      },
      "source": [
        "def summarize_results(models, root_dir, order_by=\"mean_absolute_error\"):\n",
        "    df_results = pd.DataFrame()\n",
        "    for model in models:\n",
        "        name = model[\"name\"]\n",
        "        df_path = f\"{root_dir}/{name}/history_{name}.csv\"\n",
        "        df = pd.read_csv(df_path, index_col=0)\n",
        "        max_acc_thresh = df.iloc[df[order_by].idxmax()]\n",
        "        max_idx = max_acc_thresh.name\n",
        "        max_acc_thresh = max_acc_thresh.append(\n",
        "            pd.Series({\"name\": name, \"epoch\": max_idx})\n",
        "        )\n",
        "        df_results = df_results.append(max_acc_thresh, ignore_index=True)\n",
        "\n",
        "    df_results = df_results[['name', 'epoch', order_by, 'valid_loss', 'train_loss']]\n",
        "    dest_file = f\"{root_dir}/summary\"\n",
        "    \n",
        "    print(f\"Saving to {dest_file}\")\n",
        "    df_results.to_csv(dest_file)\n",
        "\n",
        "def save_stats(learn, name):\n",
        "    p = learn.recorder.plot_losses(return_fig=True)\n",
        "    p.savefig(path.join(learn.path, 'losses'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLVyf1-umCV2",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ebucZVjDX0hG",
        "outputId": "7a80fd4e-d91d-443c-9276-87b8fad5d726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "DT_LEN = 10000\n",
        "\n",
        "for root_dir in ['./polygon_data_counts', './polygon_data']:\n",
        "    df_train = gen_df(root_dir, DT_LEN, skip=True, test=False, count=True)\n",
        "    df_test  = gen_df(root_dir, DT_LEN//2, skip=True, test=True, count=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created directory /content/polygon_data_counts/train\n",
            "Created directory /content/polygon_data_counts/train/images\n",
            "Created directory /content/polygon_data_counts/test\n",
            "Created directory /content/polygon_data_counts/test/images\n",
            "Created directory /content/polygon_data/train\n",
            "Created directory /content/polygon_data/train/images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "36jViGY-IhmN",
        "colab": {}
      },
      "source": [
        "DT_ROOT_DIR = './polygon_data_counts'\n",
        "DT_ROOT_DIR = path.abspath(DT_ROOT_DIR)\n",
        "MODEL_ROOT_DIR = path.join(DT_ROOT_DIR, 'results')\n",
        "W, H = 512, 512\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "test_item_list = (ImageList\n",
        "    .from_df(path=path.join(DT_ROOT_DIR, 'test', 'images'), df=df_test, convert_mode='1')\n",
        ")\n",
        "    \n",
        "bunch = (ImageList\n",
        "            .from_df(path=path.join(DT_ROOT_DIR, 'train', 'images'), df=df_train, convert_mode='1')\n",
        "            .split_by_rand_pct()\n",
        "            .label_from_df(cols=1, label_cls=FloatList)\n",
        "            .transform(size=(W, H))\n",
        "            .add_test(test_item_list)\n",
        "            .databunch(bs=BATCH_SIZE, device=device)  \n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXLj-hbOmCWR",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7G5A5a9mCWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_EPOCHS = 25\n",
        "EARLY_STOP_PATIENCE = 50\n",
        "REDUCE_ON_PLATEAU_PATIENCE = 25\n",
        "\n",
        "l1 = nn.MSELoss()\n",
        "loss_func = lambda i,t: l1(i.squeeze(), t)\n",
        "\n",
        "params = {\n",
        "    \"max_channels\": 3,\n",
        "    \"activation_fn\": nn.ReLU,\n",
        "    \"pool_size\": 2,\n",
        "    \"num_layers\": 8,\n",
        "    \"conv_stride\": 1\n",
        "}\n",
        "\n",
        "models = [\n",
        "    {\"model\": base_model(pool_layer=SumPool2d, **params), \"name\": \"sum_pool\"},\n",
        "    {\"model\": base_model(pool_layer=nn.MaxPool2d, **params), \"name\": \"max_pool\"},\n",
        "    {\"model\": base_model(pool_layer=nn.AvgPool2d, **params), \"name\": \"avg_pool\"}\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Esv-MVimCWe",
        "colab_type": "text"
      },
      "source": [
        "### Baseline Model (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUPujaUmCWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "metrics = [\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error\n",
        "]\n",
        "\n",
        "learn = Learner(\n",
        "    model=nn.Sequential(Flatten(), nn.Linear(W * H, 1)),\n",
        "    data=bunch,\n",
        "    path=f\"{MODEL_ROOT_DIR}/mlp\",\n",
        "    callback_fns=[\n",
        "        partial(EarlyStoppingCallback, patience=EARLY_STOP_PATIENCE), \n",
        "        partial(ReduceLROnPlateauCallback, patience=REDUCE_ON_PLATEAU_PATIENCE),\n",
        "        partial(CSVLogger, filename=f\"history_mlp\")\n",
        "    ],\n",
        "    metrics=metrics,\n",
        "    silent=True\n",
        ")\n",
        "learn.fit(MAX_EPOCHS)\n",
        "save_stats(learn, 'mlp')\n",
        "learn.save(\"mlp\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y_A4W1bDmCWo",
        "colab": {}
      },
      "source": [
        "for model in models:\n",
        "    learn = cnn_learner(\n",
        "        data=bunch,\n",
        "        path=path.join(MODEL_ROOT_DIR, model[\"name\"]),\n",
        "        base_arch=lambda t: model[\"model\"](),\n",
        "        cut=lambda x: x,\n",
        "        loss_func=loss_func,\n",
        "        callback_fns=[\n",
        "            partial(EarlyStoppingCallback, patience=EARLY_STOP_PATIENCE), \n",
        "            partial(ReduceLROnPlateauCallback, patience=REDUCE_ON_PLATEAU_PATIENCE),\n",
        "            partial(CSVLogger, filename=f\"history_{model['name']}\")\n",
        "        ],\n",
        "        metrics=metrics,\n",
        "        silent=True\n",
        "    )\n",
        "    learn.fit(MAX_EPOCHS)\n",
        "    save_stats(learn, model[\"name\"])\n",
        "    learn.save(model[\"name\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpnQmgnemCWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summarize_results([*models, {\"name\":\"mlp\"}], MODEL_ROOT_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}