{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCBJxAI4OSlh"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageStat\n",
    "from PIL.ImageDraw import ImageDraw\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from random import randint\n",
    "from math import pi\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "from fastai import vision\n",
    "from fastai.vision import ImageList, FloatList, cnn_learner, pil2tensor, open_image\n",
    "from fastai.callbacks import EarlyStoppingCallback, ReduceLROnPlateauCallback, CSVLogger\n",
    "from fastai.train import ShowGraph, Learner\n",
    "from fastai.metrics import mean_absolute_error, mean_squared_error\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcoes Auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yeben-JAOixI",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def base_model(pool_layer, pool_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5, stride=1),\n",
    "        pool_layer(pool_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(3, 6, 3, 1),\n",
    "        pool_layer(pool_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(6, 4, 2, 1),\n",
    "        pool_layer(pool_size),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "def cnn_max_pool(pool_size=2):\n",
    "    return base_model(nn.MaxPool2d, pool_size)\n",
    "\n",
    "class SumPool2d(nn.Module):\n",
    "    def __init__(self, pool_size):\n",
    "        super(SumPool2d, self).__init__()\n",
    "        self.pool_size = pool_size\n",
    "        self.area = pool_size * pool_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, self.pool_size) * self.area\n",
    "    \n",
    "def cnn_sum_pool(pool_size=2):\n",
    "    return base_model(SumPool2d, pool_size)\n",
    "\n",
    "def cnn_avg_pool(pool_size=2):\n",
    "    return base_model(nn.AvgPool2d, pool_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Generation Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yeben-JAOixI",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def random_point(w, h, minx=0, miny=0):\n",
    "    x, y = randint(minx, w), randint(miny, h)\n",
    "    return (x, y)\n",
    "\n",
    "def area_ellipse(p1, p2):\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    x_len = abs(x1 - x2)\n",
    "    y_len = abs(y1 - y2)\n",
    "    return pi * x_len * y_len\n",
    "\n",
    "def gen_example(w, h, num_polygons=1, count=False):\n",
    "    example = Image.new('1', (w, h))\n",
    "    draw = ImageDraw(example, mode='1')\n",
    "\n",
    "    total_area = w * h\n",
    "    area = 0\n",
    "    for i in range(num_polygons):\n",
    "        p1 = random_point(w, h)\n",
    "        p2 = random_point(w, h, p1[0], p1[1])\n",
    "        draw.rectangle([p1, p2], fill=1)\n",
    "\n",
    "    (area, ) = ImageStat.Stat(example).sum\n",
    "    if not count:\n",
    "        area /= total_area\n",
    "    return (example, area)\n",
    "\n",
    "def gen_df(\n",
    "        root_dir, \n",
    "        dt_len, \n",
    "        img_size=(512, 512), \n",
    "        skip=True, \n",
    "        test=False, \n",
    "        count=False):\n",
    "    root_dir = path.abspath(root_dir)\n",
    "    root_dir = path.join(root_dir, \"test\" if test else \"train\")\n",
    "    img_dir = path.join(root_dir, 'images')\n",
    "    df_dest = path.join(root_dir, 'data.csv')\n",
    "    if path.exists(df_dest) and skip:\n",
    "        print(\"Found existing dataset, skipping...\")\n",
    "        return pd.read_csv(df_dest, index_col=0)\n",
    "    \n",
    "    for directory in [root_dir, img_dir]:\n",
    "        if not path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            print(f\"Created directory {directory}\")\n",
    "\n",
    "    df = pd.DataFrame(columns=['filename', 'area'])\n",
    "    for i in range(dt_len):\n",
    "        filename = f\"img_{i}.jpeg\"\n",
    "        dest_path = path.join(img_dir, filename)\n",
    "        img, area = gen_example(*img_size, count=count)\n",
    "        img.save(dest_path)\n",
    "        row = pd.Series({\"filename\": filename, \"area\": area})\n",
    "        df.loc[i] = row\n",
    "\n",
    "    df.to_csv(df_dest)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yeben-JAOixI",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def summarize_results(models, root_dir, order_by=\"mean_absolute_error\"):\n",
    "    df_results = pd.DataFrame()\n",
    "    for model in models:\n",
    "        name = model[\"name\"]\n",
    "        df_path = f\"{root_dir}/{name}/history_{name}.csv\"\n",
    "        df = pd.read_csv(df_path, index_col=0)\n",
    "        max_acc_thresh = df.iloc[df[order_by].idxmax()]\n",
    "        max_idx = max_acc_thresh.name\n",
    "        max_acc_thresh = max_acc_thresh.append(\n",
    "            pd.Series({\"name\": name, \"epoch\": max_idx})\n",
    "        )\n",
    "        df_results = df_results.append(max_acc_thresh, ignore_index=True)\n",
    "\n",
    "    df_results = df_results[['name', 'epoch', order_by, 'valid_loss', 'train_loss']]\n",
    "    dest_file = f\"{root_dir}/summary\"\n",
    "    \n",
    "    print(f\"Saving to {dest_file}\")\n",
    "    df_results.to_csv(dest_file)\n",
    "\n",
    "def save_stats(learn, name):\n",
    "    p = learn.recorder.plot_losses(return_fig=True)\n",
    "    p.savefig(path.join(learn.path, 'losses'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ebucZVjDX0hG",
    "outputId": "84fbb8a2-3df0-4f0f-ddc3-66a7e27185a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory /home/victor/Git/areacnn/polygon_data_counts/train\n",
      "Created directory /home/victor/Git/areacnn/polygon_data_counts/train/images\n",
      "Created directory /home/victor/Git/areacnn/polygon_data_counts/test\n",
      "Created directory /home/victor/Git/areacnn/polygon_data_counts/test/images\n",
      "Created directory /home/victor/Git/areacnn/polygon_data/train\n",
      "Created directory /home/victor/Git/areacnn/polygon_data/train/images\n",
      "Created directory /home/victor/Git/areacnn/polygon_data/test\n",
      "Created directory /home/victor/Git/areacnn/polygon_data/test/images\n"
     ]
    }
   ],
   "source": [
    "DT_LEN = 10000\n",
    "\n",
    "for root_dir in ['./polygon_data_counts', './polygon_data']:\n",
    "    df_train = gen_df(root_dir, DT_LEN, skip=True, test=False, count=True)\n",
    "    df_test  = gen_df(root_dir, DT_LEN//2, skip=True, test=True, count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "36jViGY-IhmN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "DT_ROOT_DIR = './polygon_data_counts'\n",
    "DT_ROOT_DIR = path.abspath(DT_ROOT_DIR)\n",
    "MODEL_ROOT_DIR = path.join(DT_ROOT_DIR, 'results')\n",
    "W, H = 512, 512\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "test_item_list = (ImageList\n",
    "    .from_df(path=path.join(DT_ROOT_DIR, 'test', 'images'), df=df_test, convert_mode='1')\n",
    ")\n",
    "    \n",
    "bunch = (ImageList\n",
    "            .from_df(path=path.join(DT_ROOT_DIR, 'train', 'images'), df=df_train, convert_mode='1')\n",
    "            .split_by_rand_pct()\n",
    "            .label_from_df(cols=1, label_cls=FloatList)\n",
    "            .transform(size=(W, H))\n",
    "            .add_test(test_item_list)\n",
    "            .databunch(bs=BATCH_SIZE, device=device)  \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 25\n",
    "EARLY_STOP_PATIENCE = 50\n",
    "REDUCE_ON_PLATEAU_PATIENCE = 25\n",
    "\n",
    "l1 = nn.MSELoss()\n",
    "loss_func = lambda i,t: l1(i.squeeze(), t)\n",
    "\n",
    "\n",
    "models = [\n",
    "    {\"model\": cnn_sum_pool, \"name\": \"sum_pool\"},\n",
    "    {\"model\": cnn_max_pool, \"name\": \"max_pool\"},\n",
    "    {\"model\": cnn_avg_pool, \"name\": \"avg_pool\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='25', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.00% [3/25 00:31<03:48]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='31' class='' max='125', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      24.80% [31/125 00:02<00:07 816640960.0000]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "metrics = [\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error\n",
    "]\n",
    "\n",
    "learn = Learner(\n",
    "    model=nn.Sequential(Flatten(), nn.Linear(W * H, 1)),\n",
    "    data=bunch,\n",
    "    path=f\"{MODEL_ROOT_DIR}/mlp\",\n",
    "    callback_fns=[\n",
    "        partial(EarlyStoppingCallback, patience=EARLY_STOP_PATIENCE), \n",
    "        partial(ReduceLROnPlateauCallback, patience=REDUCE_ON_PLATEAU_PATIENCE),\n",
    "        partial(CSVLogger, filename=f\"history_mlp\")\n",
    "    ],\n",
    "    metrics=metrics,\n",
    "    silent=True\n",
    ")\n",
    "learn.fit(MAX_EPOCHS)\n",
    "save_stats(learn, 'mlp')\n",
    "learn.save(\"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "36jViGY-IhmN"
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    learn = cnn_learner(\n",
    "        data=bunch,\n",
    "        path=path.join(MODEL_ROOT_DIR, model[\"name\"]),\n",
    "        base_arch=lambda t: model[\"model\"](),\n",
    "        cut=lambda x: x,\n",
    "        loss_func=loss_func,\n",
    "        callback_fns=[\n",
    "            partial(EarlyStoppingCallback, patience=EARLY_STOP_PATIENCE), \n",
    "            partial(ReduceLROnPlateauCallback, patience=REDUCE_ON_PLATEAU_PATIENCE),\n",
    "            partial(CSVLogger, filename=f\"history_{model['name']}\")\n",
    "        ],\n",
    "        metrics=metrics,\n",
    "        silent=True\n",
    "    )\n",
    "    learn.fit(MAX_EPOCHS)\n",
    "    save_stats(learn, model[\"name\"])\n",
    "    learn.save(model[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_results([*models, {\"name\":\"mlp\"}], MODEL_ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "PolygonDatasetGenerator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
