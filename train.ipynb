{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageStat\n",
    "from PIL.ImageDraw import ImageDraw\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from random import randint\n",
    "from math import pi\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "from fastai import vision\n",
    "from fastai.vision import ImageList, FloatList, cnn_learner, pil2tensor, open_image\n",
    "from fastai.callbacks import EarlyStoppingCallback, ReduceLROnPlateauCallback, CSVLogger\n",
    "from fastai.train import ShowGraph, Learner\n",
    "from fastai.metrics import mean_absolute_error, mean_squared_error\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import numpy as np \n",
    "\n",
    "from functools import partial\n",
    "import itertools\n",
    "from collections import namedtuple\n",
    "\n",
    "## Local Imports ##\n",
    "from models import helpers as model_helpers, models as custom_models\n",
    "from datasets import helpers as dataset_helpers, datasets as custom_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, H = (512, 512)\n",
    "BS = 256\n",
    "DEVICE = 'cuda'\n",
    "DT_ROOT = 'data'\n",
    "POLYGON_COUNT_DIR = 'polygon_data_counts'\n",
    "POLYGON_PERCENTAGE_DIR = 'polygon_data_percentage'\n",
    "ELLIPSE_COUNT_DIR = 'ellipse_data_counts'\n",
    "ELLIPSE_PERCENTAGE_DIR = 'ellipse_data_percentage'\n",
    "\n",
    "options = {\n",
    "    \"bs\": BS,\n",
    "    \"device\": DEVICE,\n",
    "    \"transform_args\": {\"size\": (W, H)}\n",
    "}\n",
    "\n",
    "rect_counts_options = custom_datasets.gen_dataset_options(\n",
    "    root_dir=path.join(DT_ROOT, POLYGON_COUNT_DIR),\n",
    "    **options\n",
    ")\n",
    "\n",
    "rect_percentage_options = custom_datasets.gen_dataset_options(\n",
    "    root_dir=path.join(DT_ROOT, POLYGON_PERCENTAGE_DIR),\n",
    "    **options\n",
    ")\n",
    "\n",
    "ellipse_counts_options = custom_datasets.gen_dataset_options(\n",
    "    root_dir=path.join(DT_ROOT, ELLIPSE_COUNT_DIR),\n",
    "    **options\n",
    ")\n",
    "\n",
    "ellipse_percentage_options = custom_datasets.gen_dataset_options(\n",
    "    root_dir=path.join(DT_ROOT, ELLIPSE_PERCENTAGE_DIR),\n",
    "    **options\n",
    ")\n",
    "\n",
    "dataset_generators = [\n",
    "    lambda: custom_datasets.get_dataset(**rect_counts_options),\n",
    "    lambda: custom_datasets.get_dataset(**rect_percentage_options),\n",
    "    lambda: custom_datasets.get_dataset(**ellipse_counts_options),\n",
    "    lambda: custom_datasets.get_dataset(**ellipse_percentage_options)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EARLY_STOP_PATIENCE = 100\n",
    "REDUCE_ON_PLATEAU_PATIENCE = 25 \n",
    "MAX_EPOCHS = 150\n",
    "\n",
    "learner_args = {\n",
    "    \"metrics\": [\n",
    "        mean_squared_error,\n",
    "        mean_absolute_error\n",
    "    ],\n",
    "    \"callback_fns\": [\n",
    "            partial(EarlyStoppingCallback, patience=EARLY_STOP_PATIENCE), \n",
    "            partial(ReduceLROnPlateauCallback, patience=REDUCE_ON_PLATEAU_PATIENCE),\n",
    "            partial(CSVLogger, filename=f\"history_mlp\")\n",
    "        ],\n",
    "    \"silent\": True\n",
    "}\n",
    "\n",
    "OPTIMS = [\n",
    "    model_helpers.Param('Adam', torch.optim.Adam),\n",
    "    model_helpers.Param('SGD', torch.optim.SGD)\n",
    "]\n",
    "\n",
    "LOSS_FNS = [\n",
    "    model_helpers.Param('L1LOSS', nn.L1Loss),\n",
    "    model_helpers.Param('MSELOSS', nn.MSELoss)\n",
    "]\n",
    "\n",
    "models_to_test = custom_models.get_models()\n",
    "\n",
    "cnn_grid = model_helpers.new_grid_search(dataset_generators, models_to_test, OPTIMS, LOSS_FNS)\n",
    "mlp_grid = model_helpers.new_grid_search(dataset_generators, [None], OPTIMS, LOSS_FNS)\n",
    "\n",
    "## WHAT I DO WHITH DISSSS????\n",
    "squeeze_loss = lambda loss_fn: lambda x,y: loss_fn(x.view(-1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=[\"pth\", \"loss\", \"optim\", \"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='150', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/150 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='78', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/78 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "for row in mlp_grid:\n",
    "    bunch = row.dataset()\n",
    "    model_path = path.join(bunch.path,'..', '..', 'results', 'mlp', row.opt.name, row.loss.name)\n",
    "    model_path = path.abspath(model_path)\n",
    "    learn = Learner(\n",
    "        model=nn.Sequential(Flatten(), nn.Linear(W * H, 1)),\n",
    "        opt_func=row.opt.param,\n",
    "        data=bunch,\n",
    "        loss_func=squeeze_loss(row.loss.param()),\n",
    "        path=model_path,\n",
    "        **learner_args\n",
    "    )\n",
    "    learn.fit(MAX_EPOCHS)\n",
    "    model_helpers.save_stats(learn)\n",
    "    learn.save('model')\n",
    "    df_results = df_results.append({\n",
    "            \"pth\": learn.path, \n",
    "            \"loss\": row.loss.name, \n",
    "            \"optim\": row.opt.name, \n",
    "            \"val_loss\": learn.recorder.losses[-1].item()\n",
    "        }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in cnn_grid:\n",
    "    bunch = row.dataset()\n",
    "    model_path = path.join(bunch.path, '..', '..', 'results', row.model.name, row.opt.name, row.loss.name)\n",
    "    model_path = path.abspath(model_path)\n",
    "    learn = cnn_learner(\n",
    "        data=bunch,\n",
    "        path=model_path,\n",
    "        base_arch=lambda t: row.model.param,\n",
    "        cut=lambda x: x,\n",
    "        loss_func=squeeze_loss(row.loss.param()),\n",
    "        opt_func=row.opt.param,\n",
    "        **learner_args\n",
    "    )\n",
    "    learn.fit(MAX_EPOCHS)\n",
    "    model_helpers.save_stats(learn)\n",
    "    learn.save('model')\n",
    "    df_results = df_results.append({\n",
    "            \"pth\": learn.path, \n",
    "            \"loss\": row.loss.name, \n",
    "            \"optim\": row.opt.name, \n",
    "            \"val_loss\": learn.recorder.losses[-1].item()\n",
    "        }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('FULL_RESULTS.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Broken... ## \n",
    "#DT_ROOT_DIRS = map(lambda p: path.join(DT_ROOT, p, 'results'),[POLYGON_COUNT_DIR, POLYGON_PERCENTAGE_DIR])\n",
    "#for root_dir in DT_ROOT_DIRS:\n",
    "#    model_helpers.summarize_results([*models_to_test, {\"name\":\"mlp\"}], root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
