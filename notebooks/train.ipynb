{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "from random import randint\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial, reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datetime\n",
    "\n",
    "## Local Imports ##\n",
    "if '../' not in sys.path:\n",
    "    sys.path.insert(0, '../')\n",
    "from models import helpers as model_helpers, model_definitions as custom_models\n",
    "from datasets import helpers as dataset_helpers, datasets as custom_datasets\n",
    "\n",
    "from train_single_script import create_arg_str\n",
    "\n",
    "from VOC import DT_DEST_RGB_RANDOM, DT_DEST_RGB_SINGLE_CLASS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel, Width, Height\n",
    "C, W, H = (3, 128, 128)\n",
    "\n",
    "TRAIN_SINGLE_PATH = './train_single_script.py'\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "HOME = path.expanduser('~')\n",
    "DT_ROOT = path.abspath(\n",
    "    path.join('..', 'data', f'{W}x{H}')\n",
    ")\n",
    "\n",
    "POLYGON_COUNT_DIR = path.join(DT_ROOT, 'polygon_data_counts')\n",
    "POLYGON_PERCENTAGE_DIR = path.join(DT_ROOT, 'polygon_data_percentage')\n",
    "\n",
    "POLYGON_RGB_COUNT_DIR = path.join(DT_ROOT, 'polygon_RGB_counts')\n",
    "POLYGON_RGB_NOISED_COUNT_DIR = path.join(DT_ROOT, 'polygon_rgb_noised_counts')\n",
    "\n",
    "ELLIPSE_COUNT_DIR = path.join(DT_ROOT, 'ellipse_data_counts')\n",
    "ELLIPSE_PERCENTAGE_DIR = path.join(DT_ROOT, 'ellipse_data_percentage')\n",
    "\n",
    "VOC_SEGS_COUNTS_DIR = path.join(HOME, 'datasets', 'VOC_FORMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search Params ##\n",
    "RANDOM_SEARCH = False\n",
    "SEARCH_LEN = 4\n",
    "\n",
    "MODELS = custom_models.get_models((C, W, H))\n",
    "MODELS = [\n",
    "    \"UNET\",\n",
    "    \"UNET_HALF\",\n",
    "    \"RESNET_18\",\n",
    "    \"STRIDE_4\",\n",
    "    \"STRIDE_8\",\n",
    "    \"MAX_POOL_4\",\n",
    "    \"MAX_POOL_8\",\n",
    "    \"SUM_POOL_4\",\n",
    "    \"SUM_POOL_8\"\n",
    "    \n",
    "]\n",
    "\n",
    "DATASETS = [\n",
    "    #DT_DEST_RGB_RANDOM, \n",
    "    #DT_DEST_RGB_SINGLE_CLASS(\"AEROPLANE\"),\n",
    "    #VOC_SEGS_COUNTS_DIR,\n",
    "    #POLYGON_COUNT_DIR\n",
    "    POLYGON_RGB_NOISED_COUNT_DIR\n",
    "]\n",
    "\n",
    "OPTIMS = [\"ADAM\"]\n",
    "LOSS_FNS = [\"L1LOSS\"]\n",
    "LRS = [1e-2, 1e-3, 5e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train 27 models\n",
      "9 MODELS\n",
      "1 DATASETS\n",
      "1 LOSS_FNS\n",
      "1 OPTIMS\n",
      "Device: cuda\n",
      "MODELS:\n",
      "\tUNET\n",
      "\tUNET_HALF\n",
      "\tRESNET_18\n",
      "\tSTRIDE_4\n",
      "\tSTRIDE_8\n",
      "\tMAX_POOL_4\n",
      "\tMAX_POOL_8\n",
      "\tSUM_POOL_4\n",
      "\tSUM_POOL_8\n",
      "LRS:\n",
      "\t0.01\n",
      "\t0.001\n",
      "\t0.0005\n",
      "DATASETS:\n",
      "\tpolygon_rgb_noised_counts\n"
     ]
    }
   ],
   "source": [
    "grid = model_helpers.new_grid_search(MODELS, OPTIMS, LOSS_FNS, LRS)\n",
    "grid = list(grid)\n",
    "\n",
    "print(f\"Will train {len(LOSS_FNS) * len(MODELS) * len(DATASETS) * len(OPTIMS) * len(LRS)} models\")\n",
    "print(f\"{len(MODELS)} MODELS\")\n",
    "print(f\"{len(DATASETS)} DATASETS\")\n",
    "print(f\"{len(LOSS_FNS)} LOSS_FNS\")\n",
    "print(f\"{len(OPTIMS)} OPTIMS\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "models_str = '\\t' + \"\\n\\t\".join(MODELS)\n",
    "lrs_str = '\\t' + \"\\n\\t\".join(map(str, LRS))\n",
    "\n",
    "dts_str = '\\t' + \"\\n\\t\".join([dt.split('/')[-1] for dt in DATASETS])\n",
    "print(f\"MODELS:\")\n",
    "print(models_str)\n",
    "print(f\"LRS:\")\n",
    "print(lrs_str)\n",
    "print(f\"DATASETS:\")\n",
    "print(dts_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 25\n",
      "BS: 32\n",
      "Timestamp: 2020-1-5_11-44-44\n"
     ]
    }
   ],
   "source": [
    "curr_time = datetime.datetime.now()\n",
    "CURR_TIME_STR = (\n",
    "    f\"{curr_time.year}-{curr_time.month}-{curr_time.day}_\"\n",
    "    f\"{curr_time.hour}-{curr_time.minute}-{curr_time.second}\"\n",
    ")\n",
    "OUT_FILE = path.join(\"logs\", f\"out_{CURR_TIME_STR}.log\")\n",
    "MAX_EPOCHS = 25\n",
    "BS = 32\n",
    "\n",
    "BASE_ARGS = {\n",
    "    \"C\": C,\n",
    "    \"H\": H,\n",
    "    \"W\": W,\n",
    "    \"bs\": BS,\n",
    "    \"epochs\": MAX_EPOCHS,\n",
    "    \"device\": DEVICE,\n",
    "    \"id\": CURR_TIME_STR,\n",
    "    \"epochs\": MAX_EPOCHS\n",
    "}\n",
    "\n",
    "print(f\"Epochs: {MAX_EPOCHS}\")\n",
    "print(f\"BS: {BS}\")\n",
    "print(f\"Timestamp: {CURR_TIME_STR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(dts, rows, sanity):\n",
    "    if sanity: print(\"Performing sanity check...\")\n",
    "    else     : print(\"Training...\")\n",
    "    for dt in tqdm(dts):\n",
    "        for row in tqdm(rows):\n",
    "            command = (\n",
    "                f'python3 {TRAIN_SINGLE_PATH} ' + \n",
    "                create_arg_str({\n",
    "                    **BASE_ARGS,\n",
    "                    \"dataset\": dt,\n",
    "                    \"model\"  : row.model,\n",
    "                    \"optim\"  : row.opt,\n",
    "                    \"loss_fn\": row.loss,\n",
    "                    \"lr\"     : row.lr,\n",
    "                    \"sanity\" : sanity,\n",
    "                }) + f' >> {OUT_FILE}')\n",
    "            status = os.system(command)\n",
    "            if status != 0: raise RuntimeError(f'FAILED: {command}')\n",
    "    if sanity: print(\"Sanity Check: All Passed!\")\n",
    "    else     : print(\"Done Training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing sanity check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 1/27 [00:03<01:37,  3.76s/it]\u001b[A\n",
      "  7%|▋         | 2/27 [00:07<01:33,  3.75s/it]\u001b[A\n",
      " 11%|█         | 3/27 [00:11<01:30,  3.76s/it]\u001b[A\n",
      " 15%|█▍        | 4/27 [00:15<01:27,  3.79s/it]\u001b[A\n",
      " 19%|█▊        | 5/27 [00:19<01:23,  3.82s/it]\u001b[A\n",
      " 22%|██▏       | 6/27 [00:22<01:20,  3.83s/it]\u001b[A\n",
      " 26%|██▌       | 7/27 [00:26<01:15,  3.79s/it]\u001b[A\n",
      " 30%|██▉       | 8/27 [00:30<01:11,  3.77s/it]\u001b[A\n",
      " 33%|███▎      | 9/27 [00:34<01:07,  3.75s/it]\u001b[A\n",
      " 37%|███▋      | 10/27 [00:37<01:02,  3.70s/it]\u001b[A\n",
      " 41%|████      | 11/27 [00:41<00:58,  3.66s/it]\u001b[A\n",
      " 44%|████▍     | 12/27 [00:44<00:54,  3.64s/it]\u001b[A\n",
      " 48%|████▊     | 13/27 [00:48<00:50,  3.62s/it]\u001b[A\n",
      " 52%|█████▏    | 14/27 [00:51<00:46,  3.60s/it]\u001b[A\n",
      " 56%|█████▌    | 15/27 [00:55<00:43,  3.60s/it]\u001b[A\n",
      " 59%|█████▉    | 16/27 [00:58<00:38,  3.54s/it]\u001b[A\n",
      " 63%|██████▎   | 17/27 [01:02<00:34,  3.49s/it]\u001b[A\n",
      " 67%|██████▋   | 18/27 [01:05<00:31,  3.46s/it]\u001b[A\n",
      " 70%|███████   | 19/27 [01:09<00:27,  3.44s/it]\u001b[A\n",
      " 74%|███████▍  | 20/27 [01:12<00:23,  3.42s/it]\u001b[A\n",
      " 78%|███████▊  | 21/27 [01:15<00:20,  3.41s/it]\u001b[A\n",
      " 81%|████████▏ | 22/27 [01:19<00:16,  3.40s/it]\u001b[A\n",
      " 85%|████████▌ | 23/27 [01:22<00:13,  3.40s/it]\u001b[A\n",
      " 89%|████████▉ | 24/27 [01:25<00:10,  3.39s/it]\u001b[A\n",
      " 93%|█████████▎| 25/27 [01:29<00:06,  3.39s/it]\u001b[A\n",
      " 96%|█████████▋| 26/27 [01:32<00:03,  3.38s/it]\u001b[A\n",
      "100%|██████████| 27/27 [01:36<00:00,  3.56s/it]\u001b[A\n",
      "100%|██████████| 1/1 [01:36<00:00, 96.11s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: All Passed!\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 1/27 [19:50<8:35:44, 1190.18s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid_search(DATASETS, grid, sanity=True)\n",
    "    grid_search(DATASETS, grid, sanity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
