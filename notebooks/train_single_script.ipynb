{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from os import path\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "if '../' not in sys.path: sys.path.insert(0, '../')\n",
    "    \n",
    "from models import helpers as model_helpers \n",
    "from models.train import train as train_model\n",
    "from models.helpers import Param\n",
    "from models.model_definitions import get_models\n",
    "from models.metrics import METRICS\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from transform import TRANSFORM\n",
    "from datasets import datasets as custom_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMS = {\n",
    "    \"ADAM\": optim.Adam,\n",
    "    \"SGD\" : partial(optim.SGD, lr=0.005)\n",
    "}\n",
    "\n",
    "LOSS_FNS = {\n",
    "    \"L1LOSS\" : lambda: model_helpers.squeeze_loss(nn.L1Loss()),\n",
    "    \"MSELOSS\": lambda: model_helpers.squeeze_loss(nn.MSELoss())\n",
    "}\n",
    "\n",
    "RESULTS_DIR = './results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -model MODEL -optim OPTIM -loss_fn LOSS_FN\n",
      "                             -dataset DATASET -bs BS -epochs EPOCHS\n",
      "                             [-device DEVICE] -W W -H H -id ID [--sanity]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -model, -optim, -loss_fn, -dataset, -bs, -epochs, -W, -H, -id\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def create_arg_str(args):\n",
    "    return \" \".join(\n",
    "        [\n",
    "            f'-model {args[\"model\"]}',\n",
    "            f'-optim {args[\"optim\"]}',\n",
    "            f'-loss_fn {args[\"loss_fn\"]}',\n",
    "            f'-dataset {args[\"dataset\"]}',\n",
    "            f'-bs {args[\"bs\"]}',\n",
    "            f'-epochs {args[\"epochs\"]}',\n",
    "            f'-device {args[\"device\"]}',\n",
    "            f'-C {args[\"C\"]}',\n",
    "            f'-W {args[\"W\"]}',\n",
    "            f'-H {args[\"H\"]}',\n",
    "            f'-id {args[\"id\"]}',\n",
    "            f'{\"--sanity\" if args[\"sanity\"] else \"\"}',\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_params(args):\n",
    "    return {\n",
    "        \"model\": get_models((args.C, args.W, args.H))[args.model],\n",
    "        \"dataset\": Param(\n",
    "            args.dataset,\n",
    "            custom_datasets.get_dataset(\n",
    "                root_dir=args.dataset,\n",
    "                df_path=path.join(args.dataset, \"data.csv\"),\n",
    "                transform=TRANSFORM,\n",
    "                bs=args.bs,\n",
    "            ),\n",
    "        ),\n",
    "        \"optim\": Param(args.optim, OPTIMS[args.optim]),\n",
    "        \"loss_fn\": Param(args.loss_fn, LOSS_FNS[args.loss_fn]),\n",
    "        \"epochs\": args.epochs,\n",
    "        \"device\": args.device,\n",
    "    }\n",
    "\n",
    "\n",
    "def train(model, dataset, optim, loss_fn, epochs, device):\n",
    "    metrics = train_model(\n",
    "        dl_train=dataset.param.train(),\n",
    "        dl_val=dataset.param.test(),\n",
    "        model=model.param(),\n",
    "        opt_func=optim.param,\n",
    "        loss_fn=loss_fn.param(),\n",
    "        epochs=epochs,\n",
    "        device=device,\n",
    "        show_progress=False,\n",
    "    )\n",
    "\n",
    "    rows = list(\n",
    "        map(\n",
    "            lambda r: {\n",
    "                \"model_name\": model.name,\n",
    "                \"optim\": optim.name,\n",
    "                \"loss_fn\": loss_fn.name,\n",
    "                \"dataset\": dataset.name,\n",
    "                \"epoch\": r[\"epoch\"],\n",
    "                \"train_loss\": r[\"train_loss\"],\n",
    "                \"val_loss\": r[\"val_loss\"],\n",
    "                \"train_loss_avg\": r[\"train_loss_avg\"],\n",
    "                \"val_loss_avg\": r[\"val_loss_avg\"],\n",
    "                \"pct_error_avg\": r[\"pct_error_avg\"],\n",
    "            },\n",
    "            metrics,\n",
    "        )\n",
    "    )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def sanity_check(model, dl):\n",
    "    for e, l in dl.param.test():\n",
    "        try:\n",
    "            model.param()(e)\n",
    "            print(f\"Sanity check on {model.name} {dl.name} OK!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model: {model.name}\\n\" f\"Dataset: {dl.name}\\n\" f\"Exception: {e}\\n\")\n",
    "            print(f\"Sanity check on {model.name} {dl.name} FAILED!\")\n",
    "            raise e\n",
    "        break\n",
    "\n",
    "\n",
    "def main():\n",
    "    p = ArgumentParser(description=\"Train on a dataset with a CNN\")\n",
    "    p.add_argument(\"-model\", type=str, required=True, help=\"The model name\")\n",
    "    p.add_argument(\"-optim\", type=str, required=True, help=\"The optim to use\")\n",
    "    p.add_argument(\"-loss_fn\", type=str, required=True, help=\"The loss function\")\n",
    "    p.add_argument(\"-dataset\", type=str, required=True, help=\"The dataset path\")\n",
    "    p.add_argument(\"-bs\", type=int, required=True, help=\"Batch size\")\n",
    "    p.add_argument(\"-epochs\", type=int, required=True, help=\"Epochs\")\n",
    "    p.add_argument(\n",
    "        \"-device\", type=str, required=False, help=\"Torch device\", default=\"cuda\"\n",
    "    )\n",
    "    p.add_argument(\"-C\", type=int, required=True, help=\"Input channels\")\n",
    "    p.add_argument(\"-W\", type=int, required=True, help=\"Input width\")\n",
    "    p.add_argument(\"-H\", type=int, required=True, help=\"Input height\")\n",
    "    p.add_argument(\n",
    "        \"-id\", type=str, required=True, help=\"Unique id for current execution\"\n",
    "    )\n",
    "    p.add_argument(\"--sanity\", action=\"store_true\", help=\"Run single image to check\")\n",
    "    args = p.parse_args()\n",
    "    params = get_params(args)\n",
    "\n",
    "    if not path.exists(RESULTS_DIR):\n",
    "        print(f\"Creating results directory at: f{RESULTS_DIR}\")\n",
    "        os.makedirs(RESULTS_DIR)\n",
    "    if args.sanity:\n",
    "        sanity_check(model=params[\"model\"], dl=params[\"dataset\"])\n",
    "    else:\n",
    "        df = train(**params)\n",
    "        csv_dest = path.join(RESULTS_DIR, f\"{args.id}.csv\")\n",
    "        if path.exists(csv_dest):\n",
    "            print(\"Appending to existing file\")\n",
    "            old_df = pd.read_csv(csv_dest, index_col=0)\n",
    "            df = pd.concat([old_df, df], sort=False)\n",
    "            df.to_csv(csv_dest)\n",
    "        else:\n",
    "            print(f\"Saving to {csv_dest}\")\n",
    "            df.to_csv(csv_dest)\n",
    "        print(f\"Done with {args.model}, {args.dataset}, {args.loss_fn}, {args.optim}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.helpers import Param\n",
    "a = [Param('a', sum), Param('b', sum), Param('c', sum)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': <function sum(iterable, start=0, /)>,\n",
       " 'b': <function sum(iterable, start=0, /)>,\n",
       " 'c': <function sum(iterable, start=0, /)>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    **dict(a)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
