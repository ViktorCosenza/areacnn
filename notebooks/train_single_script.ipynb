{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from os import path\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "if '../' not in sys.path: sys.path.insert(0, '../')\n",
    "    \n",
    "\n",
    "from models import helpers as model_helpers \n",
    "from models.helpers import Param\n",
    "from models.models import models_to_test\n",
    "\n",
    "from datasets import datasets as custom_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMS = {\n",
    "    \"Adam\": optim.Adam,\n",
    "    \"SGD\" : optim.SGD\n",
    "}\n",
    "\n",
    "LOSS_FNS = {\n",
    "    \"L1LOSS\" : lambda: model_helpers.squeeze_loss(nn.L1Loss()),\n",
    "    \"MSELOSS\": lambda: model_helpers.squeeze_loss(nn.MSELoss())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(args):\n",
    "    print(args.transform or transforms.ToTensor())\n",
    "    return {\n",
    "        \"model\"   : models_to_test((1, args.W, args.H))[args.model], \n",
    "        \"dataset\" : \n",
    "            Param(\n",
    "                args.dataset, \n",
    "                custom_datasets.get_dataset(\n",
    "                    root_dir=args.dataset,\n",
    "                    df_path=path.join(args.dataset, 'data.csv'),\n",
    "                    transform=args.transform or transforms.Compose([transforms.ToTensor()]),\n",
    "                    bs=args.bs)),\n",
    "        \"optim\"   : Param(args.optim, OPTIMS[args.optim]),\n",
    "        \"loss_fn\" : Param(args.loss_fn, LOSS_FNS[args.loss_fn]),\n",
    "        \"epochs\"  : args.epochs,\n",
    "        \"device\"  : args.device,\n",
    "    }\n",
    "\n",
    "\n",
    "def train(model, dataset, optim, loss_fn, epochs, device):\n",
    "    metrics = model_helpers.train(\n",
    "        dl_train=dataset.param.train(),\n",
    "        dl_val  =dataset.param.test(),\n",
    "        model   =model.param(),\n",
    "        opt_func=optim.param,\n",
    "        loss_fn =loss_fn.param(),\n",
    "        epochs  =epochs,\n",
    "        device  =device\n",
    "    )\n",
    "    \n",
    "    rows = list(map(lambda r: {\n",
    "        \"model_name\"     : model.name,\n",
    "        \"optim\"          : optim.name,\n",
    "        \"loss_fn\"        : loss_fn.name,\n",
    "        \"dataset\"        : dataset.name,\n",
    "        \"epoch\"          : r[\"epoch\"],\n",
    "        \"train_loss\"     : r[\"train_loss\"],\n",
    "        \"val_loss\"       : r[\"val_loss\"],\n",
    "        \"train_loss_avg\" : r[\"train_loss_avg\"],\n",
    "        \"val_loss_avg\"   : r[\"val_loss_avg\"]}, metrics))\n",
    "    return pd.DataFrame(rows)\n",
    "    \n",
    "def main():\n",
    "    p = ArgumentParser(description='Train on a dataset with a CNN')\n",
    "    p.add_argument('-model'    , type=str, required=True , help='The model name')\n",
    "    p.add_argument('-optim'    , type=str, required=True , help='The optim to use')\n",
    "    p.add_argument('-loss_fn'  , type=str, required=True , help='The loss function')    \n",
    "    p.add_argument('-dataset'  , type=str, required=True , help='The dataset path')\n",
    "    p.add_argument('-bs'       , type=int, required=True , help='Batch size')\n",
    "    p.add_argument('-epochs'   , type=int, required=True , help=\"Epochs\")\n",
    "    p.add_argument('-device'   , type=str, required=False, help='Torch device', default='cuda')\n",
    "    p.add_argument('-transform', type=str, required=False, help='Transforms'  , default='')\n",
    "    p.add_argument('-W'        , type=int, required=True , help='Input width')\n",
    "    p.add_argument('-H'        , type=int, required=True , help='Input height')\n",
    "    p.add_argument('--sanity'  , action='store_true'     , help='Run single image to check')\n",
    "    args = p.parse_args()\n",
    "    params = get_params(args)\n",
    "    if args.sanity: model_helpers.sanity_check(params)\n",
    "    else: \n",
    "        df = train(**params)\n",
    "        csv_dest = (\n",
    "            f'{params[\"model\"].name}-'\n",
    "            f'{params[\"dataset\"].name}-'\n",
    "            f'{params[\"loss_fn\"].name}-'\n",
    "            f'{params[\"optim\"].name}.csv')\n",
    "        print(csv_dest)\n",
    "        print(df.head())\n",
    "        #df.to_csv(csv_dest)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__': main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc def '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'\\\n",
    "abc \\\n",
    "def \\\n",
    "'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
